---
title: "Big_Tech_Figures"
author: "N. Jones"
date: "10/19/2020"
output: pdf_document
---

```{r setup}
options(stringsAsFactors=F)
library(reshape2)
library(ggplot2)
```

## Topic Contribution

### Data Preparation

```{r loading_comment_data}
# read the data file
dim(d <- data_for_R_50)
# remove non-alphanumeric elements (brackets and commas)
d$topic_assignments <- gsub("\\W", " ", d$topic_assignments)
# remove multiple spaces
d$topic_assignments <- gsub(" +", " ", d$topic_assignments)
# remove the initial and final spaces
d$topic_assignments <- gsub("(^ )|( $)", "", d$topic_assignments)
# split topic assignments for each word and save the list in an array
head(d$topicList <- lapply(strsplit(d$topic_assignments, " "), as.numeric))
```

### Per-Comment Topic Contribution

```{r per_comment_topic_contrib}
# define a variable for number of topics
ntopic <- max(unlist(d$topicList))
# add month information (month index, number of comments per month) and comment information (comment length) to the dataframe d in a convenient format

d <- within(d, {
    commentLength <- sapply(topicList, length)
    yearMonth <- paste(2010 + (year-1), month)
    monthNum <- ((2010 + (year-1))-2010)*12 + month
    monthComments <- xtabs(~monthNum)[as.character(monthNum)]
})



#ERROR, for some reason instead of monNUm = 252 (21*12), = 237 which accoutns for the N/A's in dataframe "d"

# calculate per-comment topic contribution
for (topic in 0:ntopic){
    d[,paste0("t", topic)] <- sapply(d$topicList, function(comment){
        sum(comment == topic)
    }) / d$commentLength / d$monthComments
}
# head(d)
```

### Per-Month Topic Contribution

```{r per_month_topic_contrib}
# calculate per-month topic contribution
perMonth <- sapply(0:ntopic, function(topic){
    with(d, tapply(get(paste0("t", topic)), monthNum, sum, na.rm=T))
})
# rename perMonth column names and transform it into a dataframe
colnames(perMonth) <- 0:ntopic
perMonth <- as.data.frame(perMonth)
# each row in perMonth is now a month, each column associated with a topic, with the value at their intersection determining the contribution of a certain topic to comments in a certain month. The following line ensures that the calculation was done properly and contributions for each month sum to (approximately) 1:
apply(perMonth, 1, sum, na.rm=T)
# add a column with the month indices
perMonth$monthNum <- as.numeric(rownames(perMonth))
# rename rows to more interpretable month-year labels
rownames(perMonth) <- as.list(unique(d$yearMonth))
# add the labels as a separate column
perMonth$month <- rownames(perMonth)
# examine the results
dim(perMonth)
# head(perMonth)
# turn data into a long format where each month and topic combination is in a separate row
#head(allMonths <- melt(perMonth, id.vars=c("month","monthNum"), variable.name="topic", value.name="contrib"))
sub <- subset(allMonths, topic == 7 & monthNum <= 84) 
avgsum <- mean(sub$contrib)
print("mean")
avgsum

```

### Significant Temporal Trends

```{r sig_topic_trends}
# rename column names in allMonths
colnames(perMonth)[1:(length(colnames(perMonth))-2)] <- paste0("t",colnames(perMonth)[1:(length(colnames(perMonth))-2)])
# Run the cubic regression for each topic (.001 is added to the numerator and denominator of log odds to prevent potential division by zero). Also count the number of coefficients with p < 0.05

topic.ts <-
sapply(paste0("t", 0:ntopic), function(topic){
y <- perMonth[,topic]
sum(summary(lm(log((y+.001)/(1-y+.001)) ~
poly(as.numeric(perMonth$monthNum), 3)))$coefficients[-1,"Pr(>|t|)"] < .001)})

# show the number of significant coefficients for each topic
sort(topic.ts)
```

```{r load_data}
#load("/media/babak_daily/Data/Marij_Leg_Updated_New/Marijuana_Legalization_Corpus_Study/LDA_full-corpus:True_50/R_contrib_workspace.RData")
```

### Choice of Top Topics

```{r important_topics}
# take the average of per-month topic contributions
topicContrib <- sort(apply(perMonth[,0:ntopic+1], 2, mean))
# choose topics with topicContrib > .03
important <- names(topicContrib)[topicContrib > .03]
# Result: c(0,1,15,16, 19, 26, 28, 37, 44, 48, 49)
# turn the topic labels into numeric values and print
(important <- sort(as.numeric(gsub("t", "", important))))

important <- c(0,1,2,3,7,8,10,11,12,13,14,15,16,17,18,19,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,39,40,41,42,44,45,47,48,49) # those in any cluster

junk <- c(5,6,9,11,13,14,17,18,20, 22,23,24,26,30,32,38,40,41,42,43,45,46) # adjust this
important <- setdiff(0:ntopic,junk) # all but the "junk" topics
################(25)###########

   
#what about just linear trends?
(sapply(paste0("t", 0:ntopic), function(topic){
y <- perMonth[,topic]
sum(summary(lm(log((y+.001)/(1-y+.001)) ~
poly(as.numeric(perMonth$monthNum), 3)))$coefficients[2,"Pr(>|t|)"] < .05)}))
# These don't have significant linear trends: 12,14,19,25,26,42
```

#### Plot of top topics combined

```{r combined_contrib_plot}
# create interpretable labels for months
allMonths.translate <- with(allMonths, tapply(month, monthNum, unique))
allMonths.translate <- gsub(" .*", "", allMonths.translate)
# create the plot object, add proper ticks and labels
ggplot(subset(allMonths, topic %in% important),
    aes(monthNum,contrib,color=topic)) +
    geom_smooth(method=lm, formula=y ~ poly(x, 3)) +
    scale_x_continuous(name="Time",
                       breaks=c(23+(0:9)*12), labels=allMonths.translate[as.character(c(23+(0:9)*12))]) +
  theme_bw() +
  ylab("Percentage contribution") +
  scale_color_discrete("Topics") 
  # include vertical lines for important events (must be identified)
  # geom_vline(xintercept=75) + 
  # geom_vline(xintercept=112) 

```

## Discourse Categories

### Obsolete code for human ratings

Run the entire file, but ignore sections under this header.

#### Load Human Ratings

```{r load_human_ratings}
# load sample_keys and sample_ratings
sample_keys <- read.csv("C:\\Users\\Babak\\Downloads\\sample_keys.csv" )
# sample_ratings <- read.csv("C:\\Users\\Babak\\Desktop\\Ratings\\sample_ratings_final_1.csv") 
# warning! File changed from the original
sample_ratings <- read.csv("C:\\Users\\Babak\\Downloads\\sample_ratings.csv") 
# remove non-relevant comments prior to analysis
sample_ratings$interpretability[sample_ratings$interpretability == 'n'] <- 0
sample_ratings$interpretability[sample_ratings$interpretability != 0] <- 1
sample_ratings$interpretability <- as.numeric(sample_ratings$interpretability)
# sample_ratings <- subset(sample_ratings,interpretability == 1) # wrong file loaded for 12.28.18 analysis
# change the column name for the random index, so that the keys and ratings can be merged using those IDs
colnames(sample_keys)[2] <- 'index'
# merge sample_keys and sample_ratings
dim(combined_key <- merge(sample_keys, sample_ratings, by ='index'))
# rename column header for consistency across the dataframes
colnames(combined_key)[2] <- 'number'
```

#### Determine Top Comment Classification Certainty

```{r non_dominant_top_topic_avg_contrib}
# merge sampled comment information with data abiyt the most likely topic for each word
# dim(with_topics <- merge(combined_key,d,by='number'))
with_topics <- d
# # The merging resulted in two copies of year and month. Here I remove the duplicate columns and rename the original ones
# with_topics$year.y <- NULL
# with_topics$month.y <- NULL
# colnames(with_topics)[3] <- 'month'
# colnames(with_topics)[4] <- 'year'
# create a matrix where each row is a top topic (in order of topic number) and each column is a sampled post. The values show the number of words in a sampled post assigned to a topic
top_counts <- sapply(important, function(top){sapply(with_topics$topicList, function(nums){sum(nums == top)})})
top_counts <- t(top_counts)
colnames(top_counts) <- 1:length(top_counts[1,])
# create a vector containing the fraction of words in each comment that belong to non-dominant top topics
other_top_contrib = rep(0, length(top_counts[1,]))
for (i in 1:length(top_counts[1,])){
  other_top_contrib[i] = (sum(top_counts[,i]) - max(top_counts[,i])) / sum(top_counts[,i])
}
# calculate the average fraction, as well as the standard deviation
mean(as.matrix(other_top_contrib))
sd(as.matrix(other_top_contrib))
```

#### Discourse Categories Based on Human Ratings

```{r categorize_discourse_type_per_topic}
# # determine the number of comments sampled for each topic that have a higher value-based rating than consequence-based and other
# value_dominant <- with(with_topics,sapply(important, function(top){sum(I(topic == top & values > consequences & values > other))}))
# # determine the number of comments sampled for each topic that have a higher consequence-based rating than value-based and other
# conseq_dominant <- with(with_topics,sapply(important, function(top){sum(I(topic == top & consequences > values & consequences > other))}))
# # the number of comments sampled for each topic that were deemed relevant to same-sex marriage by the raters
# # valid_counts <- as.matrix(xtabs(~topic,subset(with_topics,interpretability == 1))) # wrong file loaded that doesn't have interpretability ratings on 12.28.18
# # determine the number of comments sampled for each topic that have a higher "other" rating than consequence-based and value-based
# valid_counts <- 250 # fake
# neut_dominant <- 0 #valid_counts - (value_dominant+conseq_dominant) # fake
# determine the discourse category associated with each topic based on the described criteria

discourse_cats <- ifelse((value_dominant > conseq_dominant) & (value_dominant > neut_dominant) & (value_dominant > (valid_counts / 2)),"values",ifelse((conseq_dominant > value_dominant) & (conseq_dominant > neut_dominant) & (conseq_dominant > valid_counts / 2),"consequences","neutral"))
# bind the different matrices together into a data frame
disc_cats <- data.frame(cbind(as.numeric(important),value_dominant,conseq_dominant,neut_dominant,valid_counts,discourse_cats))
# rename the column labels for interpretability
colnames(disc_cats) <- c('topic','values','consequences','neutral','valid','categories')
# print the classifications
(disc_cats[,c(1,6)])
```

#### Discourse Categories and Support for Same-sex Marriage

```{r pro_against}
pro_against <- xtabs(~with_topics$pro,with_topics)
years <- xtabs(~with_topics$year,with_topics)
(pro_dist <- as.matrix(xtabs(~with_topics$topic+with_topics$pro,with_topics)))
```

### Discourse Category Regression and Plot

The following code has been adjusted to classify and plot topics based on results of ten ten-fold cross-validations rather than obsolete human ratings data (see readme.txt for more details).

```{r not_summed_discourse}
# choose only the month-topic rows in allMonths that are associated with a top topic
# only_important <- subset(allMonths,topic %in% important) #12.28.18: include all topics
only_important <- allMonths
# add discourse category ratings and classifications to the newly formed data frame
# only_important <- merge(only_important,disc_cats) # orig file needed for disc_cats changed
# Drop topic 44
# only_important <- subset(only_important, topic != 44) # marijuana one. Don't need this anyway for the latest analysis
# Add a column to only_important with the discourse category associated with each topic
# only_important$discourse_category <- ifelse(only_important$topic %in% c(12,48),"value",ifelse(only_important$topic %in% c(22,23,28),"conseq","neutral"))
# ADDED FOR THE NEW TOP TOPIC ANALYSIS
# c(23,47,28,22,4,14,27) conseq., first two below 50, last one 100
# c(29,12,48,49) val., first one below 50, the last three 100

only_important$discourse_category <- ifelse(only_important$topic %in% c(3,6,37),"Antitrust","neither")

# ifelse(only_important$topic %in% c(1,8,9,46),"NEW TECH",ifelse(only_important$topic %in% c(11,18,30,43),"POLITICS",ifelse(only_important$topic %in% c(7,13),"POSITIVE CHANGES (bad title)",ifelse(only_important$topic %in% c(3,6,37),"ANTITRUST",ifelse(only_important$topic %in% c(12,45),"INVESTMENTS IN TECH",ifelse(only_important$topic %in% c(29),"FINTECH",ifelse(only_important$topic %in% c(32,44),"LEGISLATIVE PROTECTION",ifelse(only_important$topic %in% c(2,39),"NEW TECH POLICY",ifelse(only_important$topic %in% c(20,21),"PLATFORM CONTENT",ifelse(only_important$topic %in% c(24,26),"INNOVATIONS",ifelse(only_important$topic %in% c(0,36),"REAL ESTATE AND ANTITRUST (JUNK?)",ifelse(only_important$topic %in% c(31),"COVID",ifelse(only_important$topic %in% c(22,38),"ECONOMY",ifelse(only_important$topic %in% c(14,16,40,42),"GROWTH","neither"))))))))))))))

only_important <- subset(only_important,discourse_category != "neither") 
```

### Reported Value-based vs. Consequence-based Categorizations

#### Pooled contribution estimates

```{r pooled_logodds_top_words_distributions}
# re-define discourse categories assigned to topics
only_important$discourse_category <- as.factor(ifelse(only_important$topic %in% c(8,22),"Antitrust","neither"))
# pool topic contributions within each discourse category and save the result along with dates to a new data frame
bymonth <- aggregate(contrib ~ month + monthNum + discourse_category, only_important, sum)
# calculate the percentage contribution of all top topics to each month's posts and add the resulting value to the recently created data-frame (bymonth). These values will be used in the calculation of log odds
bymonth_allcontrib <- aggregate(contrib ~ month + monthNum, only_important,sum)
bymonth$allcontrib <- bymonth_allcontrib$contrib
# Distribution of discourse category contributions to posts in the dataset
summary(bymonth)
# Summary of the contributions of all top topics to posts in the dataset
summary(bymonth_allcontrib$contrib)
```

## Main Trend Results

Includes topics reported in the paper

### Regression

```{r pooled_logodds_top_words_regression}
# linear regression with log odds of a discourse category's pooled contribution as the predicted value and discourse_category*timestep as the predictors
bymonth$log_odds <- log(bymonth$contrib/(bymonth$allcontrib-bymonth$contrib))
bymonth$discourse_category_new <- ifelse(bymonth$discourse_category == "conseq",1,0)
poly_qr <- with(bymonth,(lm(log_odds ~ polym(discourse_category_new, monthNum, degree=3, raw=TRUE))))
```

### Plots

#### Discourse Categories

The following chunk produces a plot of the pooled discourse category contributions, along with the best-fitting local polynomial regression line.

```{r pooled_top_words_plot}
ggplot(subset(bymonth, bymonth$monthNum >= 0), aes(x=monthNum, y=contrib, color=discourse_category)) + geom_point() + geom_smooth(span=0.4,size = 1) +
  scale_x_continuous(name="Time", breaks=seq(0,250,12), labels=as.character(c(2000 :2020))) +
  theme_light() +
  theme(legend.text=element_text(size=12)) +
  geom_point(size = 0.1) +
  ylab("Proportion contribution") +
   scale_color_manual(values=c("blue"),labels=c("Antitrust")) +
  labs(fill="Discourse Category")
```

#### Growth Topics

The following plot shows the trends associated with individual value-based topics. 

```{r govt_econ_plot}

#Interesting: 
ggplot(subset(subset(allMonths, monthNum >= 0), topic %in% c(15)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(0,130,12), labels=as.character(c(2010:2020))) +
  scale_fill_manual(values=c("black")) +
  scale_color_manual(values=c("black"),labels = c("Critiques of Capitalsim")) +
  theme_bw() +
  geom_point(size = 0.1) +
  ylab("Percentage contribution")

```


#### Consumer Protection Topics

The following plot shows the trends associated with individual consumer protection topics.

```{r comp_plot}
ggplot(subset(subset(allMonths, monthNum >= 121), topic %in% c(2,16)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(121,250,12), labels=as.character(c(2010:2020))) +
  scale_fill_manual(values=c("red", "black")) +
  scale_color_manual(values=c("red","black"),labels = c("Consumer Protection Law","Antitrust")) +
  theme_bw() +
  geom_point(size = 0.1) +
  # geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.06), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.06), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.06), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.06), colour="black", angle=90, text=element_text(size=5)) + 
  #  #geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.06), colour="black", angle=90, text=element_text(size=5)) + 
  #  #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
# Events Lengend: 
# A: Doudna and Charpentier, 2012 
# B: Non-viable human embryo
# C: First in humans
# D: Viable human embryo
# E: Crispr babies scandal
```

#### Investigation Topics

```{r everyday_plot}
ggplot(subset(subset(allMonths, monthNum >= 121), topic %in% c(5,13,15)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(121,250,12), labels=as.character(c(2010:2020))) +
  scale_fill_manual(values=c("purple", "brown", "pink")) +
  scale_color_manual(values=c("purple", "brown", "pink"),labels = c("International Big Tech","BT Investigations","New Business")) +
  theme_bw() +
  geom_point(size = 0.1) +
  # geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.18), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.18), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.18), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.18), colour="black", angle=90, text=element_text(size=5)) + 
  #  #geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.18), colour="black", angle=90, text=element_text(size=5)) + 
  #  #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
```

```{r ind_exp_plot}
#AL/FinTech: 7,22
ggplot(subset(subset(allMonths, monthNum >= 121), topic %in% c(7,22)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(121,250,12), labels=as.character(c(2010:2020))) +
  scale_fill_manual(values=c("red", "blue")) +
  scale_color_manual(values=c("red", "blue"),labels = c("FinTech","AI Development")) +
  theme_bw() +
  geom_point(size = 0.1) +
  #  geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.045), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  # # geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.045), colour="black", angle=90, text=element_text(size=5))+
   #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
```
```{r ind_exp_plot}
# Content: 8,19,20
ggplot(subset(subset(allMonths, monthNum >= 0), topic %in% c(13)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(0,250,12), labels=as.character(c(2000:2020))) +
  scale_fill_manual(values=c("red")) +
  scale_color_manual(values=c("red"),labels = c("Positive Words")) +
  theme_bw() +
  geom_point(size = 0.1) +
  #  geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.045), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  # # geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.045), colour="black", angle=90, text=element_text(size=5))+
   #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
```

```{r ind_exp_plot}
# Section 230 
ggplot(subset(subset(allMonths, monthNum >= 0), topic %in% c(36)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(0,250,12), labels=as.character(c(2000:2020))) +
  scale_fill_manual(values=c("purple")) +
  scale_color_manual(values=c("purple"),labels = c("antitrust")) +
  theme_bw() +
  geom_point(size = 0.1) +
  #  geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.045), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  # # geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.045), colour="black", angle=90, text=element_text(size=5))+
   #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
```



```{r ind_exp_plot}
# China
ggplot(subset(subset(allMonths, monthNum >= 0), topic %in% c(31)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(0,250,12), labels=as.character(c(2000:2020))) +
  scale_fill_manual(values=c("black")) +
  scale_color_manual(values=c("black"),labels = c("CIOVID")) +
  theme_bw() +
  geom_point(size = 0.1) +
  #  geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.045), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  # # geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.045), colour="black", angle=90, text=element_text(size=5))+
   #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
```



```{r ind_exp_plot}
# SIngle-Topic-Figures
ggplot(subset(subset(allMonths, monthNum >= 0), topic %in% c(2,20,21,32,39,44)),
       aes(monthNum,contrib,color=topic)) +
  geom_smooth(span=0.4) +
  scale_x_continuous(name="Time", breaks=seq(0,250,12), labels=as.character(c(2000:2020))) +
  scale_fill_manual(values=c("red", "blue", "pink", "green", "purple", "black")) +
  scale_color_manual(values=c("red", "blue", "pink", "green", "purple", "black"),labels = c("New Tech in Business", "Facebook", "Platform Content","Legislative Protection", "New Tech Policy", "Privacy/Personal Data" )) +
  theme_bw() +
  geom_point(size = 0.1) +
  #  geom_vline(xintercept=55) + 
  #  geom_text(aes(x=55, label="\nA", y=.045), colour="black", angle=90, text=element_text(size=5)) +
  #  geom_vline(xintercept=88) + 
  #  geom_text(aes(x=88, label="\nB", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=108) +
  # geom_text(aes(x=108, label="\nC", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  #  geom_vline(xintercept=117) +
  #  geom_text(aes(x=117, label="\nD", y=.045), colour="black", angle=90, text=element_text(size=5)) + 
  # # geom_vline(xintercept=123) +
  #  #geom_vline(xintercept=127) +
  #  geom_vline(xintercept=131) +
  #  geom_text(aes(x=131, label="\nE", y=.045), colour="black", angle=90, text=element_text(size=5))+
   #geom_vline(xintercept=135) + 
  ylab("Percentage contribution")
```
